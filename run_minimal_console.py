"""
Complete integrated solution for Precise Predictor Console Runner.
Combines backtesting, future prediction generation, and accurate P&L reporting.
"""
from __future__ import annotations

import argparse
import datetime as dt
import hashlib
import json
import os
import subprocess
import sys
import time
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import warnings

import pandas as pd
import numpy as np

from bet_pnl_tracker import (
    MAX_PICKS_CAP_DEFAULT,
    PnLConfig,
    SLOT_NAME_MAP,
    build_effective_dates,
    compute_daily_pnl_summary,
    compute_pnl_report,
    format_andar_bahar_gating,
    format_hero_weakest,
    format_tag_roi,
    format_topk_profit,
    format_rank_bucket_windows,
    format_cross_slot_hits,
    load_clean_bet_rows,
    load_prebuilt_metrics,
    prebuilt_metrics_status,
    rebuild_prebuilt_metrics,
    aggregate_metrics,
)
from quant_data_core import load_results_dataframe
from regime_state_helper import compute_ab_gate_snapshot

SCRIPT_ORDER = [
    "deepseek_scr1.py",
    "deepseek_scr2.py",
    "deepseek_scr3.py",
    "deepseek_scr4.py",
    "deepseek_scr5.py",
    "deepseek_scr6.py",
    "deepseek_scr7.py",
    "deepseek_scr8.py",
    "deepseek_scr9.py",
]

OUTPUT_DIR = Path("predictions/deepseek_scr9")
HISTORY_PATH = OUTPUT_DIR / "scr9_shortlist_history.csv"
SLOT_NAME_TO_ID = {v: k for k, v in SLOT_NAME_MAP.items()}
PREBUILT_DIR = Path("reports/prebuilt_metrics")


# ============================================================================
# OUTPUT FORMATTING FUNCTIONS
# ============================================================================

def print_header(title: str) -> None:
    """Print header with consistent formatting."""
    print(f"\n{'='*50}")
    print(title)
    print(f"{'='*50}")

def print_section(title: str) -> None:
    """Print section header."""
    print(f"\n{title}")

def print_line(text: str = "") -> None:
    """Print a line."""
    print(text)

def print_daily_header(date_str: str) -> None:
    """Print daily prediction header."""
    print(f"\nðŸ“… Generating predictions for {date_str}...")
    print("-" * 50)

def print_backtest_header(mode: str, details: str = "") -> None:
    """Print backtest mode header."""
    print_header(f"BACKTEST MODE: {mode}")
    if details:
        print(details)
    print("-" * 50)

def print_future_header(start_date: str, end_date: str) -> None:
    """Print future predictions header."""
    print_header("FUTURE PREDICTIONS GENERATION")
    print(f"Starting from: {start_date}")
    print(f"Ending at: {end_date}")
    print("-" * 50)


# ============================================================================
# CORE UTILITY FUNCTIONS
# ============================================================================

def parse_ddmmyy(value: str) -> dt.date:
    """Parse date strings in DD-MM-YY format to date objects."""
    return dt.datetime.strptime(value.strip(), "%d-%m-%y").date()

def _format_ddmmyy(value: dt.date) -> str:
    return value.strftime("%d-%m-%y")

def _resolve_ab_cutoff_date(prediction_date: dt.date, ab_cutoff: str) -> dt.date:
    if ab_cutoff == "same":
        return prediction_date
    return prediction_date - dt.timedelta(days=1)

def _is_month_end(d: dt.date) -> bool:
    """Check if a date is the last day of the month."""
    next_day = d + dt.timedelta(days=1)
    return next_day.month != d.month

def _load_shortlist() -> pd.DataFrame:
    """Load the shortlist generated by SCR9."""
    shortlist_path = OUTPUT_DIR / "scr9_shortlist.csv"
    if not shortlist_path.exists():
        raise FileNotFoundError(f"Shortlist not found: {shortlist_path}")
    return pd.read_csv(shortlist_path)

def _load_shortlist_for_date(target_date: dt.date) -> pd.DataFrame:
    """Load the saved shortlist for a specific historical date."""
    date_dir = OUTPUT_DIR / target_date.strftime("%Y-%m-%d")
    xlsx_path = date_dir / "shortlist.xlsx"
    csv_path = date_dir / "shortlist.csv"
    
    if xlsx_path.exists():
        return pd.read_excel(xlsx_path)
    elif csv_path.exists():
        return pd.read_csv(csv_path)
    else:
        raise FileNotFoundError(f"No saved predictions found for {target_date.strftime('%d-%m-%y')}")

def _run_scripts_quietly(
    project_root: Path,
    cutoff_date: Optional[dt.date] = None,
    *,
    scr_timeout: int = 300,
    scr_retries: int = 1,
    scr2_date: Optional[dt.date] = None,
) -> None:
    """Run all SCR scripts (1-9) quietly without printing output."""
    env = os.environ.copy()
    if cutoff_date is not None:
        env["PREDICTOR_CUTOFF_DATE"] = cutoff_date.strftime("%Y-%m-%d")
    else:
        env.pop("PREDICTOR_CUTOFF_DATE", None)
    
    for script in SCRIPT_ORDER:
        script_path = project_root / script
        if not script_path.exists():
            continue
        
        try:
            subprocess.run(
                [sys.executable, str(script_path)],
                capture_output=True,
                text=True,
                cwd=project_root,
                env=env,
                timeout=300
            )
        except Exception:
            pass

def _strongest_candidates(shortlist: pd.DataFrame) -> List[Tuple[str, int]]:
    """Extract the strongest Andar/Bahar digit candidate for each slot."""
    candidates = []
    for slot_name in SLOT_NAME_TO_ID.keys():
        slot_data = shortlist[shortlist["slot"] == slot_name]
        if not slot_data.empty:
            top_row = slot_data.iloc[0]
            number = int(top_row["number"])
            candidates.append((slot_name, number))
    return candidates

def _slot_bet_lines(shortlist: pd.DataFrame, trim_notes: List[str]) -> List[str]:
    """Format bet numbers per slot with pick counts."""
    lines = []
    for slot_name in SLOT_NAME_TO_ID.keys():
        slot_data = shortlist[shortlist["slot"] == slot_name]
        if not slot_data.empty:
            num_picks = len(slot_data)
            # Show all numbers
            top_numbers = slot_data["number"].tolist()
            numbers_str = " ".join([f"{int(n):02d}" for n in top_numbers])
            
            # Find trimming note for this slot
            trim_note = ""
            for note in trim_notes:
                if note.startswith(slot_name):
                    if "â†’" in note:
                        parts = note.split("â†’")
                        if len(parts) == 2:
                            original = parts[0].split()[-1]
                            final = parts[1].split()[0]
                            trim_note = f", trimmed {original}â†’{final}"
                            break
            
            lines.append(f"{slot_name} ({num_picks}{trim_note}): {numbers_str}")
    
    return lines

def _apply_max_cap(shortlist: pd.DataFrame, k_auto_map: Optional[Dict[int, int]]) -> tuple[pd.DataFrame, List[str]]:
    """Apply K-AUTO cap to limit picks per slot based on historical performance."""
    if shortlist.empty:
        return shortlist, []
    
    if not k_auto_map:
        k_auto_map = {}
    
    trimmed = shortlist.copy()
    notes: List[str] = []
    
    for slot_name in SLOT_NAME_TO_ID.keys():
        group = shortlist[shortlist["slot"] == slot_name]
        if group.empty:
            continue
        
        slot_id = SLOT_NAME_TO_ID.get(slot_name)
        if slot_id is None:
            continue
        
        cap = k_auto_map.get(slot_id, MAX_PICKS_CAP_DEFAULT)
        original_count = len(group)
        
        if len(group) <= cap:
            continue
        
        # Sort by rank (lower is better)
        group_sorted = group.sort_values("rank", ascending=True)
        keep_indices = group_sorted.head(cap).index
        drop_indices = group_sorted.tail(len(group) - cap).index
        
        trimmed = trimmed.drop(drop_indices)
        notes.append(f"{slot_name}: trimmed {original_count}â†’{cap} (K-AUTO)")
    
    return trimmed, notes

def _prepare_predictions(shortlist: pd.DataFrame, prediction_date: dt.date) -> pd.DataFrame:
    """Prepare predictions dataframe with date and slot information."""
    if shortlist.empty:
        return pd.DataFrame()
    
    shortlist = shortlist.copy()
    shortlist["date"] = prediction_date
    shortlist["slot_name"] = shortlist["slot"]
    shortlist["slot"] = shortlist["slot"].map(SLOT_NAME_TO_ID)
    shortlist["number"] = shortlist["number"].astype(int)
    
    # Ensure rank column exists
    if "rank" not in shortlist.columns:
        # Create rank based on order in each slot
        shortlist["rank"] = 1
        for slot_name in SLOT_NAME_TO_ID.keys():
            slot_mask = shortlist["slot_name"] == slot_name
            if slot_mask.any():
                shortlist.loc[slot_mask, "rank"] = range(1, slot_mask.sum() + 1)
    
    return shortlist

def _save_shortlist_with_history(shortlist: pd.DataFrame, prediction_date: dt.date) -> None:
    """Save shortlist with historical tracking."""
    date_folder = OUTPUT_DIR / prediction_date.strftime("%Y-%m-%d")
    date_folder.mkdir(parents=True, exist_ok=True)
    
    shortlist.to_csv(date_folder / "shortlist.csv", index=False)
    shortlist.to_excel(date_folder / "shortlist.xlsx", index=False)
    
    shortlist_copy = shortlist.copy()
    shortlist_copy["prediction_date"] = prediction_date.strftime("%Y-%m-%d")
    
    if HISTORY_PATH.exists():
        history_df = pd.read_csv(HISTORY_PATH)
        history_df = pd.concat([history_df, shortlist_copy], ignore_index=True)
    else:
        history_df = shortlist_copy
    
    HISTORY_PATH.parent.mkdir(parents=True, exist_ok=True)
    history_df.to_csv(HISTORY_PATH, index=False)

def _get_latest_result_date() -> Optional[dt.date]:
    """Get the latest result date from Excel file."""
    results_df = load_results_dataframe()
    if results_df.empty:
        return None
    results_df["DATE"] = pd.to_datetime(results_df["DATE"], errors="coerce").dt.date
    results_df = results_df[~results_df["DATE"].apply(_is_month_end)]
    dates = [d for d in results_df["DATE"].tolist() if isinstance(d, dt.date)]
    return max(dates) if dates else None

def get_last_prediction_date() -> Optional[dt.date]:
    """Get the last prediction date from dated prediction folders."""
    date_candidates: List[dt.date] = []
    if OUTPUT_DIR.exists():
        for entry in OUTPUT_DIR.iterdir():
            if not entry.is_dir():
                continue
            try:
                parsed = dt.datetime.strptime(entry.name, "%Y-%m-%d").date()
                date_candidates.append(parsed)
            except ValueError:
                continue
    return max(date_candidates) if date_candidates else None


# ============================================================================
# DAILY REPORT FUNCTIONS (FIXED CALCULATIONS)
# ============================================================================

def _calculate_daily_pnl_for_date(target_date: dt.date, cfg: PnLConfig) -> Optional[Dict]:
    """Calculate P&L for a specific date with accurate calculations."""
    try:
        # Load predictions for the date
        shortlist = _load_shortlist_for_date(target_date)
        if shortlist.empty:
            return None
        
        # Prepare predictions
        preds = _prepare_predictions(shortlist, target_date)
        if preds.empty:
            return None
        
        cutoff_date = target_date - dt.timedelta(days=1)
        gate_snapshot = compute_ab_gate_snapshot(cutoff_date)
        return compute_daily_pnl_summary(
            preds,
            target_date,
            cfg,
            gate_by_day={target_date: gate_snapshot},
        )
        
    except Exception as e:
        print(f"Error calculating P&L for {target_date}: {e}")
        return None

def _format_daily_pnl_table(daily_data: Dict) -> List[str]:
    """Format daily P&L table with proper alignment."""
    lines = []
    
    # Header with fixed formatting
    lines.append("ðŸ’° YESTERDAY'S P&L ({})".format(daily_data["date"].strftime('%d-%m-%y')))
    lines.append("Slot    Result  Picks  Stake  Return   P&L     ROI      AB    AB P&L")
    lines.append("----    ------  -----  -----  ------   ----    ---      --    ------")
    
    slot_data = daily_data["slot_data"]
    totals = daily_data["totals"]
    
    for slot_name in ["FRBD", "GZBD", "GALI", "DSWR"]:
        if slot_name in slot_data:
            data = slot_data[slot_name]
            hit_marker = " [HIT]" if data["hit"] else " [MISS]"
            lines.append(
                f"{slot_name:<6}  {data['actual']:02d}  "
                f"{data['picks']:>5}  {data['stake']:>5.0f}  "
                f"{data['return']:>6.0f}  {data['pnl']:>+5.0f}  "
                f"{data['roi']:>+5.0f}%  "
                f"{data['ab_status']:>3}  {data['ab_pnl']:>+5.0f}{hit_marker}"
            )
    
    # Total line with proper spacing
    lines.append("-" * 70)
    lines.append(
        f"Total: {totals['picks']:>15} {totals['stake']:>5.0f}  "
        f"{totals['return']:>6.0f}  {totals['pnl']:>+5.0f}  "
        f"{totals['roi']:>+5.0f}%  {totals['ab_pnl']:>19.0f}"
    )
    
    return lines

def _calculate_correct_performance_rollups(
    target_date: dt.date,
    cfg: PnLConfig,
    expected_day_stake: Optional[float] = None,
) -> List[str]:
    """Calculate correct performance rollups using historical data."""
    lines = []
    
    # Load historical data for last 60 days (to ensure we have enough for 30D)
    start_date = target_date - dt.timedelta(days=60)
    results_df = load_results_dataframe()
    results_df["DATE"] = pd.to_datetime(results_df["DATE"], errors="coerce").dt.date
    results_df = results_df[~results_df["DATE"].apply(_is_month_end)]
    available_dates = [d for d in results_df["DATE"].tolist() if isinstance(d, dt.date)]
    effective_dates = build_effective_dates(start_date, target_date, available_dates=available_dates)

    predictions: List[pd.DataFrame] = []
    for day in effective_dates:
        try:
            shortlist = _load_shortlist_for_date(day)
        except FileNotFoundError:
            continue
        preds = _prepare_predictions(shortlist, day)
        if not preds.empty:
            predictions.append(preds)

    if not predictions:
        lines.append("\nðŸ“ˆ PERFORMANCE ROLLUPS")
        lines.append("No historical data available")
        return lines

    predictions_df = pd.concat(predictions, ignore_index=True)
    predictions_df["date"] = pd.to_datetime(predictions_df["date"], errors="coerce").dt.date
    preds_for_report = predictions_df[predictions_df["date"] <= target_date]
    if available_dates:
        preds_for_report = preds_for_report[preds_for_report["date"].isin(set(available_dates))]

    if preds_for_report.empty:
        lines.append("\nðŸ“ˆ PERFORMANCE ROLLUPS")
        lines.append("No historical data available")
        return lines

    gate_snapshot = compute_ab_gate_snapshot(target_date - dt.timedelta(days=1))
    pnl_report = compute_pnl_report(
        preds_for_report,
        cfg,
        gate_by_day={target_date: gate_snapshot},
    )

    def summarize_windows(merged: pd.DataFrame) -> List[Tuple[str, float, float, float]]:
        if merged.empty:
            return []

        merged_dates = pd.to_datetime(merged["date"], errors="coerce").dt.date
        merged = merged.assign(date=merged_dates)

        day_totals = (
            merged.groupby("date")[["cost", "pnl"]]
            .sum()
            .reset_index()
            .sort_values("date")
        )

        windows: List[Tuple[str, float, float, float]] = []

        day_entry = day_totals[day_totals["date"] == target_date]
        if not day_entry.empty:
            day_stake = float(day_entry["cost"].iloc[0])
            day_pnl = float(day_entry["pnl"].iloc[0])
            day_roi = (day_pnl / day_stake * 100) if day_stake > 0 else 0
            windows.append(("Day", day_stake, day_pnl, day_roi))

        seven_days_ago = target_date - dt.timedelta(days=6)
        week_entries = day_totals[day_totals["date"] >= seven_days_ago]
        if not week_entries.empty:
            week_stake = float(week_entries["cost"].sum())
            week_pnl = float(week_entries["pnl"].sum())
            week_roi = (week_pnl / week_stake * 100) if week_stake > 0 else 0
            windows.append(("7D", week_stake, week_pnl, week_roi))

        thirty_days_ago = target_date - dt.timedelta(days=29)
        month_entries = day_totals[day_totals["date"] >= thirty_days_ago]
        if not month_entries.empty:
            month_stake = float(month_entries["cost"].sum())
            month_pnl = float(month_entries["pnl"].sum())
            month_roi = (month_pnl / month_stake * 100) if month_stake > 0 else 0
            windows.append(("30D", month_stake, month_pnl, month_roi))

        cumulative_stake = float(day_totals["cost"].sum())
        cumulative_pnl = float(day_totals["pnl"].sum())
        cumulative_roi = (cumulative_pnl / cumulative_stake * 100) if cumulative_stake > 0 else 0
        windows.append(("Cumulative", cumulative_stake, cumulative_pnl, cumulative_roi))

        return windows

    windows = summarize_windows(pnl_report.merged)
    if not windows:
        lines.append("\nðŸ“ˆ PERFORMANCE ROLLUPS")
        lines.append("No historical data available")
        return lines

    if expected_day_stake and windows:
        day_window = next((entry for entry in windows if entry[0] == "Day"), None)
        if day_window:
            day_stake = day_window[1]
            if expected_day_stake > 0 and (
                day_stake > expected_day_stake * 2
                or expected_day_stake > day_stake * 2
            ):
                preds_for_day = preds_for_report[preds_for_report["date"] == target_date]
                if not preds_for_day.empty:
                    pnl_report = compute_pnl_report(
                        preds_for_day,
                        cfg,
                        gate_by_day={target_date: gate_snapshot},
                    )
                    windows = summarize_windows(pnl_report.merged)
    
    # Format output
    lines.append("\nðŸ“ˆ PERFORMANCE ROLLUPS")
    lines.append("Period      Status  Stake     P&L        ROI")
    lines.append("-------     ------  -----     ----       ---")
    
    def get_status(roi: float) -> str:
        if roi > 10:
            return "[GOOD]"
        elif roi > 0:
            return "[OK]"
        else:
            return "[BAD]"
    
    def format_stake(stake: float) -> str:
        if stake >= 1000:
            return f"{stake/1000:.1f}K"
        return f"{stake:.0f}"
    
    for window_name, stake, pnl, roi in windows:
        if stake == 0:
            continue
            
        status = get_status(roi)
        stake_fmt = format_stake(stake)
        lines.append(f"{window_name:<11} {status:<7} Stake: {stake_fmt:<5} P&L: {pnl:>+7.0f} ROI: {roi:>+5.1f}%")
    
    return lines

def generate_detailed_daily_report(prediction_date: dt.date, cfg: PnLConfig) -> str:
    """Generate a detailed daily report for the previous day with no duplicate sections."""
    try:
        # Get the previous day
        prev_date = prediction_date - dt.timedelta(days=1)
        
        # Load results to check if prev_date exists
        results_df = load_results_dataframe()
        results_df["DATE"] = pd.to_datetime(results_df["DATE"], errors="coerce").dt.date
        
        if prev_date not in results_df["DATE"].values:
            return f"\nNo results available for {prev_date.strftime('%d-%m-%y')} (previous day)"
        
        # Calculate daily P&L
        daily_data = _calculate_daily_pnl_for_date(prev_date, cfg)
        if not daily_data:
            return f"\nNo predictions found for {prev_date.strftime('%d-%m-%y')} (previous day)"
        
        # Build the report
        report_lines = []
        report_lines.append("=" * 50)
        report_lines.append("DAILY REPORT")
        report_lines.append("=" * 50)
        
        # Add P&L table
        pnl_table = _format_daily_pnl_table(daily_data)
        report_lines.extend(pnl_table)
        
        # Add Best Top-K Strategy
        pnl_report = daily_data["pnl_report"]
        if not pnl_report.merged.empty:
            topk_slot_lines, topk_day_lines = format_topk_profit(
                pnl_report.merged, 
                effective_dates=[prev_date],
                unit_stake=cfg.cost_per_unit
            )
            if topk_day_lines:
                report_lines.append("")
                report_lines.extend(topk_day_lines)
        
        # Add Andar/Bahar Gate
        if not pnl_report.slot_digit_hits.empty:
            gate_lines, _ = format_andar_bahar_gating(
                pnl_report.slot_digit_hits,
                cfg,
                effective_dates=[prev_date]
            )
            if gate_lines:
                report_lines.append("")
                report_lines.extend(gate_lines)
        
        # Add Rank Buckets
        try:
            # Get historical data for last 60 days
            start_hist = prev_date - dt.timedelta(days=60)
            hist_rows = load_clean_bet_rows(start_hist, prev_date, cfg)
            if not hist_rows.empty:
                effective_dates = build_effective_dates(start_hist, prev_date)
                rank_lines, k_auto_map = format_rank_bucket_windows(hist_rows, effective_dates)
                if rank_lines and "SKIP" not in rank_lines[0]:
                    report_lines.append("")
                    report_lines.extend(rank_lines)
        except Exception:
            pass
        
        # Add Tag ROI
        try:
            if 'hist_rows' in locals() and not hist_rows.empty:
                tag_lines = format_tag_roi(hist_rows, effective_dates, cfg.cost_per_unit)
                if tag_lines and "SKIP" not in tag_lines[0]:
                    report_lines.append("")
                    report_lines.extend(tag_lines)
        except Exception:
            pass
        
        # Add Cross-Slot Hits
        try:
            if 'hist_rows' in locals() and not hist_rows.empty:
                cross_lines = format_cross_slot_hits(hist_rows, effective_dates)
                if cross_lines and "No data" not in cross_lines[0]:
                    report_lines.append("")
                    report_lines.extend(cross_lines)
        except Exception:
            pass
        
        # Add Hero/Avoid Scripts
        try:
            if 'hist_rows' in locals() and not hist_rows.empty:
                metrics_30d = aggregate_metrics(hist_rows, window_days=30, effective_dates=effective_dates)
                if not metrics_30d.empty:
                    hero_lines = format_hero_weakest({'30d': metrics_30d}, min_bets=20)
                    if hero_lines:
                        report_lines.append("")
                        report_lines.extend(hero_lines)
        except Exception:
            pass
        
        # Add Performance Rollups (FIXED)
        rollup_lines = _calculate_correct_performance_rollups(
            prev_date,
            cfg,
            expected_day_stake=daily_data["totals"]["stake"],
        )
        report_lines.extend(rollup_lines)
        
        # Add notes
        report_lines.append("\nðŸ“ NOTES")
        report_lines.append(f"â€¢ Daily report generated on {dt.datetime.now().strftime('%d-%m-%Y %H:%M')}")
        
        return "\n".join(report_lines)
        
    except Exception as e:
        return f"\nError generating daily report: {str(e)}"


# ============================================================================
# BACKTEST FUNCTIONS (FIXED CALCULATIONS)
# ============================================================================

@dataclass
class BacktestDayResult:
    date: dt.date
    stake: float
    returns: float
    pnl: float
    roi: float
    hits: int
    ab_stake: float
    ab_returns: float
    ab_pnl: float
    ab_hits: int

@dataclass
class BacktestSlotResult:
    slot: str
    stake: float
    returns: float
    pnl: float
    roi: float
    hits: int
    ab_pnl: float
    total_pnl: float
    total_roi: float

def run_backtest_date_range(
    start_date: dt.date,
    end_date: dt.date,
    auto_generate_missing: bool = True,
    ab_cutoff: str = "same",
    scr_timeout: int = 300,
    scr_retries: int = 1,
) -> None:
    """
    Run backtest for a specific date range with accurate calculations.
    """
    print_backtest_header("Date Range", 
                         f"Window: {start_date.strftime('%d-%m-%y')} â†’ {end_date.strftime('%d-%m-%y')}")
    
    # Load results
    results_df = load_results_dataframe()
    results_df["DATE"] = pd.to_datetime(results_df["DATE"], errors="coerce").dt.date
    results_df = results_df[~results_df["DATE"].apply(_is_month_end)]
    
    slot_columns = list(SLOT_NAME_TO_ID.keys())
    results_df = results_df.dropna(subset=slot_columns)
    
    if results_df.empty:
        print("ERROR: No usable result dates available")
        return
    
    mask = (results_df["DATE"] >= start_date) & (results_df["DATE"] <= end_date)
    date_range_df = results_df[mask]
    
    if date_range_df.empty:
        print(f"ERROR: No results available in date range {start_date.strftime('%d-%m-%y')} to {end_date.strftime('%d-%m-%y')}")
        return
    
    available_dates = sorted(date_range_df["DATE"].unique())
    total_days = len(available_dates)
    
    print(f"Backtest window: {start_date.strftime('%d-%m-%y')} â†’ {end_date.strftime('%d-%m-%y')}")
    print(f"Days to process: {total_days}")
    
    cfg = PnLConfig()
    k_auto_map = {slot_id: MAX_PICKS_CAP_DEFAULT for slot_id in SLOT_NAME_MAP.keys()}
    
    try:
        effective_dates = build_effective_dates(start_date, end_date, available_dates=available_dates)
        bet_rows = load_clean_bet_rows(start_date, end_date, cfg)
        
        if not bet_rows.empty:
            _, loaded_k_auto_map = format_rank_bucket_windows(bet_rows, effective_dates)
            if loaded_k_auto_map:
                k_auto_map.update(loaded_k_auto_map)
                print(f"K-AUTO limits loaded: {', '.join([f'{SLOT_NAME_MAP[sid]}={cap}' for sid, cap in k_auto_map.items()])}")
    except Exception:
        print(f"Using default cap of {MAX_PICKS_CAP_DEFAULT} for all slots")
    
    print("-" * 50)
    
    project_root = Path(__file__).resolve().parent
    all_predictions: List[pd.DataFrame] = []
    gate_by_day: Dict[dt.date, Dict[int, bool]] = {}
    
    # Process each day
    for i, current_date in enumerate(available_dates):
        print(f"Processing {current_date.strftime('%d-%m-%y')} ({i+1}/{total_days})...")
        
        cutoff_date = _resolve_ab_cutoff_date(current_date, ab_cutoff)
        gate_snapshot = compute_ab_gate_snapshot(cutoff_date)
        gate_by_day[current_date] = gate_snapshot
        
        # Try to load existing predictions
        try:
            shortlist = _load_shortlist_for_date(current_date)
        except FileNotFoundError:
            if auto_generate_missing:
                # Generate predictions for this day
                _run_scripts_quietly(
                    project_root,
                    cutoff_date=current_date - dt.timedelta(days=1),
                    scr_timeout=scr_timeout,
                    scr_retries=scr_retries,
                    scr2_date=current_date,
                )
                try:
                    shortlist = _load_shortlist()
                    shortlist, _ = _apply_max_cap(shortlist, k_auto_map)
                    _save_shortlist_with_history(shortlist, current_date)
                except Exception:
                    continue
            else:
                continue
        
        if shortlist is None or shortlist.empty:
            continue
        
        preds = _prepare_predictions(shortlist, current_date)
        if preds.empty:
            continue
        
        all_predictions.append(preds)
    
    if not all_predictions:
        print("No predictions to analyze")
        return
    
    # Combine all predictions
    predictions_df = pd.concat(all_predictions, ignore_index=True)
    
    # Calculate P&L report
    pnl_report = compute_pnl_report(predictions_df, cfg, gate_by_day=gate_by_day)
    
    # Calculate daily results with accurate AB calculations
    daily_results: List[BacktestDayResult] = []
    for date in sorted(predictions_df["date"].unique()):
        gate_snapshot = gate_by_day.get(date, {})
        daily_summary = compute_daily_pnl_summary(
            predictions_df,
            date,
            cfg,
            gate_by_day={date: gate_snapshot},
        )
        if not daily_summary:
            continue
        totals = daily_summary["totals"]

        daily_results.append(BacktestDayResult(
            date=date,
            stake=totals["stake"],
            returns=totals["return"],
            pnl=totals["pnl"],
            roi=totals["roi"],
            hits=totals["hits"],
            ab_stake=totals["ab_stake"],
            ab_returns=totals["ab_return"],
            ab_pnl=totals["ab_pnl"],
            ab_hits=totals["ab_hits"],
        ))
    
    # Calculate slot results
    slot_results: List[BacktestSlotResult] = []
    for slot_id, slot_name in SLOT_NAME_MAP.items():
        slot_preds = pnl_report.merged[pnl_report.merged["slot"] == slot_id]
        slot_ab = pnl_report.digit_pnl[pnl_report.digit_pnl["slot"] == slot_id]
        
        stake = slot_preds["cost"].sum() if not slot_preds.empty else 0
        returns = slot_preds["payout"].sum() if not slot_preds.empty else 0
        pnl = returns - stake
        roi = (pnl / stake * 100) if stake > 0 else 0
        hits = int(slot_preds["hit"].sum()) if not slot_preds.empty else 0
        
        ab_pnl = slot_ab["pnl"].sum() if not slot_ab.empty else 0
        total_pnl = pnl + ab_pnl
        total_stake = stake + (slot_ab["cost"].sum() if not slot_ab.empty else 0)
        total_roi = (total_pnl / total_stake * 100) if total_stake > 0 else 0
        
        slot_results.append(BacktestSlotResult(
            slot=slot_name,
            stake=stake,
            returns=returns,
            pnl=pnl,
            roi=roi,
            hits=hits,
            ab_pnl=ab_pnl,
            total_pnl=total_pnl,
            total_roi=total_roi
        ))
    
    # Calculate overall totals
    total_stake = sum(day.stake for day in daily_results)
    total_returns = sum(day.returns for day in daily_results)
    total_pnl = total_returns - total_stake
    total_roi = (total_pnl / total_stake * 100) if total_stake > 0 else 0
    total_hits = sum(day.hits for day in daily_results)
    
    total_ab_stake = sum(day.ab_stake for day in daily_results)
    total_ab_returns = sum(day.ab_returns for day in daily_results)
    total_ab_pnl = total_ab_returns - total_ab_stake
    total_ab_roi = (total_ab_pnl / total_ab_stake * 100) if total_ab_stake > 0 else 0
    total_ab_hits = sum(day.ab_hits for day in daily_results)
    
    total_combined_pnl = total_pnl + total_ab_pnl
    total_combined_stake = total_stake + total_ab_stake
    total_combined_roi = (total_combined_pnl / total_combined_stake * 100) if total_combined_stake > 0 else 0
    
    # Print results
    print_header("BACKTEST COMPLETE")
    
    # Day-by-day summary with fixed formatting
    print("\nDAY-BY-DAY SUMMARY:")
    print("Date        Stake    Return   P&L      ROI%     ABRet  ABPnL  TotPnL  TotROI")
    print("----        -----    ------   ----     ----     -----  -----  ------  ------")
    
    for day in daily_results:
        total_day_pnl = day.pnl + day.ab_pnl
        total_day_stake = day.stake + day.ab_stake
        total_day_roi = (total_day_pnl / total_day_stake * 100) if total_day_stake > 0 else 0
        
        print(
            f"{day.date.strftime('%d-%m-%y'):<11}  {day.stake:>6.0f}  "
            f"{day.returns:>8.0f}  {day.pnl:>+7.0f}  "
            f"{day.roi:>+6.1f}%  "
            f"{day.ab_returns:>6.0f}  {day.ab_pnl:>+6.0f}  {total_day_pnl:>+7.0f}  "
            f"{total_day_roi:>+6.1f}%"
        )
    
    # Overall summary
    print(f"\nOVERALL SUMMARY ({len(daily_results)} days):")
    print(f"Total Stake:    â‚¹{total_stake:.0f}")
    print(f"Total Return:   â‚¹{total_returns:.0f}")
    print(f"Total P&L:      â‚¹{total_pnl:+.0f}")
    print(f"Overall ROI:    {total_roi:+.1f}%")
    print(f"AB Stake:       â‚¹{total_ab_stake:.0f}")
    print(f"AB Return:      â‚¹{total_ab_returns:.0f}")
    print(f"AB P&L:         â‚¹{total_ab_pnl:+.0f}")
    print(f"AB ROI:         {total_ab_roi:+.1f}%")
    print(f"Total P&L:      â‚¹{total_combined_pnl:+.0f}")
    print(f"Total ROI:      {total_combined_roi:+.1f}%")
    print(f"Total Hits:     {total_hits}")
    print(f"Hit Rate:       {(total_hits / (len(daily_results) * 4) * 100):.1f}%")
    
    # Per-slot summary with fixed formatting
    print(f"\nPER-SLOT SUMMARY:")
    print("Slot    Stake    Return   P&L      ROI%     ABRet  ABPnL  TotPnL  TotROI   Hits")
    print("----    -----    ------   ----     ----     -----  -----  ------  ------  ----")
    
    for slot in slot_results:
        slot_id = SLOT_NAME_TO_ID[slot.slot]
        ab_returns = pnl_report.digit_pnl[pnl_report.digit_pnl["slot"] == slot_id]["payout"].sum()
        print(
            f"{slot.slot:<6}  {slot.stake:>6.0f}  {slot.returns:>8.0f}  "
            f"{slot.pnl:>+7.0f}  {slot.roi:>+6.1f}%  {ab_returns:>6.0f}  "
            f"{slot.ab_pnl:>+6.0f}  {slot.total_pnl:>+7.0f}  "
            f"{slot.total_roi:>+6.1f}%  {slot.hits:>4}"
        )
    
    # Performance Rollups (correct calculation)
    try:
        # Calculate rollups from the backtest data
        rollup_lines = ["\nðŸ“ˆ PERFORMANCE ROLLUPS"]
        rollup_lines.append("Period      Status  Stake     P&L        ROI")
        rollup_lines.append("-------     ------  -----     ----       ---")
        
        # Determine status based on ROI
        def get_status(roi: float) -> str:
            if roi > 10:
                return "[GOOD]"
            elif roi > 0:
                return "[OK]"
            else:
                return "[BAD]"
        
        # Format stake with K suffix for thousands
        def format_stake(stake: float) -> str:
            if stake >= 1000:
                return f"{stake/1000:.1f}K"
            return f"{stake:.0f}"
        
        # Day window
        if daily_results:
            last_day = daily_results[-1]
            day_status = get_status(last_day.roi)
            day_stake_fmt = format_stake(last_day.stake)
            rollup_lines.append(f"Day         {day_status:<7} Stake: {day_stake_fmt:<5} P&L: {last_day.pnl:>+7.0f} ROI: {last_day.roi:>+5.1f}%")
        
        # 7D window
        if len(daily_results) >= 7:
            last_7 = daily_results[-7:]
            stake_7d = sum(day.stake for day in last_7)
            pnl_7d = sum(day.pnl for day in last_7)
            roi_7d = (pnl_7d / stake_7d * 100) if stake_7d > 0 else 0
            status_7d = get_status(roi_7d)
            stake_7d_fmt = format_stake(stake_7d)
            rollup_lines.append(f"7D          {status_7d:<7} Stake: {stake_7d_fmt:<5} P&L: {pnl_7d:>+7.0f} ROI: {roi_7d:>+5.1f}%")
        else:
            rollup_lines.append(f"7D          [N/A]   INSUFFICIENT DATA")
        
        # Month window (30D)
        if len(daily_results) >= 30:
            last_30 = daily_results[-30:]
            stake_30d = sum(day.stake for day in last_30)
            pnl_30d = sum(day.pnl for day in last_30)
            roi_30d = (pnl_30d / stake_30d * 100) if stake_30d > 0 else 0
            status_30d = get_status(roi_30d)
            stake_30d_fmt = format_stake(stake_30d)
            rollup_lines.append(f"Month       {status_30d:<7} Stake: {stake_30d_fmt:<5} P&L: {pnl_30d:>+7.0f} ROI: {roi_30d:>+5.1f}%")
        else:
            rollup_lines.append(f"Month       [N/A]   INSUFFICIENT DATA")
        
        # Cumulative window (all days in backtest)
        if daily_results:
            cumulative_stake = total_stake
            cumulative_pnl = total_pnl
            cumulative_roi = total_roi
            cumulative_status = get_status(cumulative_roi)
            cumulative_stake_fmt = format_stake(cumulative_stake)
            rollup_lines.append(f"Cumulative  {cumulative_status:<7} Stake: {cumulative_stake_fmt:<5} P&L: {cumulative_pnl:>+7.0f} ROI: {cumulative_roi:>+5.1f}%")
        
        for line in rollup_lines:
            print(line)
            
    except Exception as e:
        print(f"\nError calculating performance rollups: {e}")
    
    # Save report
    start_str = start_date.strftime("%Y%m%d")
    end_str = end_date.strftime("%Y%m%d")
    report_path = Path(f"reports/backtest_{start_str}_{end_str}.txt")
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Write detailed report
    with open(report_path, 'w') as f:
        f.write(f"BACKTEST REPORT: {start_date} to {end_date}\n")
        f.write("="*50 + "\n")
        f.write("\nDAY-BY-DAY SUMMARY:\n")
        for day in daily_results:
            f.write(f"{day.date}: Stake={day.stake:.0f}, Return={day.returns:.0f}, "
                   f"P&L={day.pnl:+.0f}, ROI={day.roi:+.1f}%, "
                   f"AB P&L={day.ab_pnl:+.0f}, Hits={day.hits}\n")
        f.write(f"\nTotal Stake: â‚¹{total_stake:.0f}\n")
        f.write(f"Total Return: â‚¹{total_returns:.0f}\n")
        f.write(f"Total P&L: â‚¹{total_pnl:+.0f}\n")
        f.write(f"Overall ROI: {total_roi:+.1f}%\n")
    
    print(f"\nReport saved to: {report_path}")


def run_backtest(
    num_days: int,
    rebuild_metrics: bool = False,
    auto_generate_missing: bool = True,
    ab_cutoff: str = "same",
    scr_timeout: int = 300,
    scr_retries: int = 1,
) -> None:
    """Run backtest for the last N days from results file."""
    print_backtest_header(f"Last {num_days} Days",
                         f"Auto-generate missing predictions: {'ON' if auto_generate_missing else 'OFF'}")
    
    results_df = load_results_dataframe()
    results_df["DATE"] = pd.to_datetime(results_df["DATE"], errors="coerce").dt.date
    results_df = results_df[~results_df["DATE"].apply(_is_month_end)]
    
    slot_columns = list(SLOT_NAME_TO_ID.keys())
    results_df = results_df.dropna(subset=slot_columns)
    
    if results_df.empty:
        print("ERROR: No usable result dates available")
        return
    
    available_dates = sorted(results_df["DATE"].unique(), reverse=True)
    if len(available_dates) < num_days:
        print(f"WARNING: Only {len(available_dates)} days available, testing all of them")
        num_days = len(available_dates)
    
    backtest_dates = available_dates[:num_days]
    start_date = min(backtest_dates)
    end_date = max(backtest_dates)
    
    run_backtest_date_range(
        start_date,
        end_date,
        auto_generate_missing=auto_generate_missing,
        ab_cutoff=ab_cutoff,
        scr_timeout=scr_timeout,
        scr_retries=scr_retries,
    )


# ============================================================================
# FUTURE PREDICTION FUNCTIONS
# ============================================================================

def generate_future_predictions_range(
    start_date: dt.date,
    end_date: dt.date,
    dry_run: bool = False,
    ab_cutoff: str = "same",
    scr_timeout: int = 300,
    scr_retries: int = 1,
) -> None:
    """Generate predictions for a specific date range."""
    print_future_header(_format_ddmmyy(start_date), _format_ddmmyy(end_date))
    
    total_days = (end_date - start_date).days + 1
    if total_days <= 0:
        print("ERROR: End date must be on or after start date")
        return

    if dry_run:
        print("DRY RUN: No files will be written.")
        print(f"Total days to process: {total_days}")
        return
    
    print(f"Total days to process: {total_days}")
    
    cfg = PnLConfig()
    k_auto_map = {slot_id: MAX_PICKS_CAP_DEFAULT for slot_id in SLOT_NAME_MAP.keys()}
    
    try:
        results_df = load_results_dataframe()
        results_df["DATE"] = pd.to_datetime(results_df["DATE"], errors="coerce").dt.date
        results_df = results_df[~results_df["DATE"].apply(_is_month_end)]
        
        if not results_df.empty:
            available_dates = sorted([d for d in results_df["DATE"].dropna().tolist() if d < start_date])
            
            if available_dates:
                history_end = max(available_dates)
                history_start = history_end - dt.timedelta(days=30)
                
                effective_dates = build_effective_dates(history_start, history_end, available_dates=available_dates)
                bet_rows = load_clean_bet_rows(history_start, history_end, cfg)
                
                if not bet_rows.empty:
                    _, loaded_k_auto_map = format_rank_bucket_windows(bet_rows, effective_dates)
                    if loaded_k_auto_map:
                        k_auto_map.update(loaded_k_auto_map)
                        print(f"K-AUTO limits from historical data: {', '.join([f'{SLOT_NAME_MAP[sid]}={cap}' for sid, cap in k_auto_map.items()])}")
    except Exception:
        print(f"Using default cap of {MAX_PICKS_CAP_DEFAULT} for all slots")
    
    print("-" * 50)
    
    project_root = Path(__file__).resolve().parent
    processed = 0
    
    # Process each day
    for day_num in range(total_days):
        prediction_date = start_date + dt.timedelta(days=day_num)
        
        if _is_month_end(prediction_date):
            print(f"SKIP: {prediction_date.strftime('%d-%m-%y')} is month-end")
            continue
        
        print_daily_header(prediction_date.strftime('%d-%m-%y'))
        
        cutoff_date = prediction_date - dt.timedelta(days=1)
        _run_scripts_quietly(
            project_root,
            cutoff_date=cutoff_date,
            scr_timeout=scr_timeout,
            scr_retries=scr_retries,
            scr2_date=prediction_date,
        )
        
        try:
            shortlist = _load_shortlist()
            if not shortlist.empty:
                shortlist, trim_notes = _apply_max_cap(shortlist, k_auto_map)
                _save_shortlist_with_history(shortlist, prediction_date)
                
                # Print predictions
                candidates = _strongest_candidates(shortlist)
                print_section("âœ… STRONGEST ANDAR/BAHAR DIGITS")
                for slot_name, number in candidates:
                    tens = number // 10
                    ones = number % 10
                    print(f"{slot_name} â†’ {number:02d} (tens:{tens}, ones:{ones})")
                
                print_section("ðŸ“Š FINAL BET NUMBERS")
                bet_lines = _slot_bet_lines(shortlist, trim_notes)
                for line in bet_lines:
                    print(line)
                
                if trim_notes:
                    print_section("ðŸ”§ K-AUTO LIMITS APPLIED")
                    for note in trim_notes:
                        print(f"  {note}")
                
                # Generate and print DAILY REPORT for previous day
                daily_report = generate_detailed_daily_report(prediction_date, cfg)
                if daily_report:
                    print(daily_report)
                
                # REMOVED BETTING SUMMARY - IT'S USELESS
                
                date_folder = OUTPUT_DIR / prediction_date.strftime("%Y-%m-%d")
                print(f"\nâœ… Predictions saved to: {date_folder}")
                
                processed += 1
            else:
                print(f"âš ï¸  No predictions generated for {prediction_date.strftime('%d-%m-%y')}")
                
        except FileNotFoundError as e:
            print(f"âŒ Error: {e}")
        except Exception as e:
            print(f"âŒ Unexpected error: {e}")
    
    print_header("FUTURE PREDICTIONS GENERATION COMPLETE!")
    print(f"Successfully generated predictions for {processed} days")
    print(f"Check folder: {OUTPUT_DIR}")


# ============================================================================
# INTERACTIVE MODE
# ============================================================================

def run_interactive_display(
    scr_timeout: int = 300,
    scr_retries: int = 1,
) -> None:
    """Run interactive display mode."""
    print_header("PRECISE PREDICTOR CONSOLE")
    
    project_root = Path(__file__).resolve().parent
    results_df = load_results_dataframe()
    result_dates = pd.to_datetime(results_df["DATE"], errors="coerce").dropna().dt.date.tolist()
    aligned_results = [d for d in result_dates if not _is_month_end(d)]
    
    if not aligned_results:
        print("âŒ SKIP: No usable result dates available")
        return
    
    latest_date = max(aligned_results)
    prediction_date = latest_date + dt.timedelta(days=1)
    
    # Skip month-ends
    while _is_month_end(prediction_date):
        prediction_date += dt.timedelta(days=1)
    
    print(f"\nðŸ“… Generating predictions for {prediction_date:%d-%m-%y}...")
    print("-" * 50)

    _run_scripts_quietly(
        project_root,
        cutoff_date=latest_date,
        scr_timeout=scr_timeout,
        scr_retries=scr_retries,
        scr2_date=prediction_date,
    )
    
    try:
        shortlist = _load_shortlist()
        
        cfg = PnLConfig()
        k_auto_map = {slot_id: MAX_PICKS_CAP_DEFAULT for slot_id in SLOT_NAME_MAP.keys()}
        
        shortlist, trimmed_notes = _apply_max_cap(shortlist, k_auto_map)
        _save_shortlist_with_history(shortlist, prediction_date)
        
        candidates = _strongest_candidates(shortlist)
        
        print_section("âœ… STRONGEST ANDAR/BAHAR DIGITS")
        for slot_name, number in candidates:
            tens = number // 10
            ones = number % 10
            print(f"{slot_name} â†’ {number:02d} (tens:{tens}, ones:{ones})")
        
        print_section("ðŸ“Š FINAL BET NUMBERS")
        bet_lines = _slot_bet_lines(shortlist, trimmed_notes)
        for line in bet_lines:
            print(line)
        
        if trimmed_notes:
            print_section("ðŸ”§ K-AUTO LIMITS APPLIED")
            for note in trimmed_notes:
                print(f"  {note}")
        
        # Generate and print DAILY REPORT for previous day
        daily_report = generate_detailed_daily_report(prediction_date, cfg)
        if daily_report:
            print(daily_report)
        
        # REMOVED BETTING SUMMARY - IT'S USELESS
        
        print(f"\nâœ… Daily report saved to: reports/daily_report_auto.txt")
        
    except FileNotFoundError:
        print("âŒ Error: Shortlist not found")
    except Exception as e:
        print(f"âŒ Error: {e}")


# ============================================================================
# COMMAND LINE HANDLING
# ============================================================================

def handle_backtest_mode(args) -> None:
    """Handle all backtest command variations."""
    # Interactive mode - no args provided
    if args.last is None and args.start is None and args.end is None:
        print_header("BACKTEST - INTERACTIVE MODE")
        
        print("Select backtest option:")
        print("  [1] Last N days")
        print("  [2] Custom date range (DD-MM-YY)")
        print("  [3] Cancel")
        
        choice = input("\nEnter choice (1-3): ").strip()
        
        if choice == "1":
            try:
                num_days = int(input("Enter number of days to backtest: ").strip())
                rebuild = input("Rebuild metrics? (y/n): ").strip().lower() == 'y'
                run_backtest(
                    num_days,
                    rebuild_metrics=rebuild,
                    auto_generate_missing=args.auto_generate_missing,
                    ab_cutoff=args.ab_cutoff,
                    scr_timeout=args.scr_timeout,
                    scr_retries=args.scr_retries,
                )
            except ValueError:
                print("ERROR: Invalid number of days")
                sys.exit(1)
        elif choice == "2":
            try:
                start_str = input("Enter start date (DD-MM-YY): ").strip()
                end_str = input("Enter end date (DD-MM-YY): ").strip()
                start_date = parse_ddmmyy(start_str)
                end_date = parse_ddmmyy(end_str)
                rebuild = input("Rebuild metrics? (y/n): ").strip().lower() == 'y'
                
                run_backtest_date_range(
                    start_date,
                    end_date,
                    auto_generate_missing=args.auto_generate_missing,
                    ab_cutoff=args.ab_cutoff,
                    scr_timeout=args.scr_timeout,
                    scr_retries=args.scr_retries,
                )
            except ValueError as e:
                print(f"ERROR: {e}")
                sys.exit(1)
        elif choice == "3":
            print("Cancelled")
            sys.exit(0)
        else:
            print("ERROR: Invalid choice")
            sys.exit(1)
        return
    
    # Date range mode
    if args.start and args.end:
        try:
            start_date = parse_ddmmyy(args.start)
            end_date = parse_ddmmyy(args.end)
            
            run_backtest_date_range(
                start_date,
                end_date,
                auto_generate_missing=args.auto_generate_missing,
                ab_cutoff=args.ab_cutoff,
                scr_timeout=args.scr_timeout,
                scr_retries=args.scr_retries,
            )
        except ValueError as e:
            print(f"ERROR: {e}")
            sys.exit(1)
        return
    
    # Last N days mode
    if args.last is not None:
        if args.last <= 0:
            print("ERROR: --last must be a positive integer")
            sys.exit(1)
        run_backtest(
            args.last,
            rebuild_metrics=args.rebuild_metrics,
            auto_generate_missing=args.auto_generate_missing,
            ab_cutoff=args.ab_cutoff,
            scr_timeout=args.scr_timeout,
            scr_retries=args.scr_retries,
        )
        return
    
    # Invalid combination
    print("ERROR: --backtest requires either --last N or --start and --end")
    sys.exit(1)


def handle_future_generation_mode(args) -> None:
    """Handle all future generation command variations."""
    # Custom date range mode (both --from and --to provided)
    if args.from_date and args.to_date:
        try:
            start_date = parse_ddmmyy(args.from_date)
            end_date = parse_ddmmyy(args.to_date)
            
            generate_future_predictions_range(
                start_date,
                end_date,
                dry_run=args.dry_run,
                ab_cutoff=args.ab_cutoff,
                scr_timeout=args.scr_timeout,
                scr_retries=args.scr_retries,
            )
        except ValueError as e:
            print(f"ERROR: {e}")
            sys.exit(1)
        return
    
    # Auto-detect mode with optional rebuild (no date arguments)
    if not args.from_date and not args.to_date:
        print_header("GENERATE FUTURE PREDICTIONS - AUTO-DETECT MODE")
        
        try:
            latest_excel_date = _get_latest_result_date()
            last_prediction_date = get_last_prediction_date()
            
            if not latest_excel_date:
                print("Bad date inference")
                sys.exit(1)

            print(f"Latest Excel data: {_format_ddmmyy(latest_excel_date)}")
            if last_prediction_date:
                print(f"Last prediction:   {_format_ddmmyy(last_prediction_date)}")
            else:
                print(f"Last prediction:   None found")
            
            # Calculate gap and next date
            if last_prediction_date and last_prediction_date < latest_excel_date:
                gap_days = (latest_excel_date - last_prediction_date).days
                print(f"\nâš ï¸  Gap detected: {gap_days} days between last prediction and latest data")
                print(
                    f"Will backfill: {_format_ddmmyy(last_prediction_date + dt.timedelta(days=1))} "
                    f"to {_format_ddmmyy(latest_excel_date)}"
                )
                
                backfill_start = last_prediction_date + dt.timedelta(days=1)
                backfill_end = latest_excel_date
            else:
                backfill_start = None
                backfill_end = None
            
            # Next day (future prediction)
            next_day = latest_excel_date + dt.timedelta(days=1)
            while _is_month_end(next_day):
                next_day += dt.timedelta(days=1)
            print(f"Next day (future): {_format_ddmmyy(next_day)}")
            
            print("\nWhat would you like to do?")
            print("  [1] Generate predictions (backfill gap + next day only)")
            print("  [2] Custom date range (manual input)")
            print("  [3] Cancel")
            
            choice = input("\nEnter choice (1-3): ").strip()
            
            if choice == "1":
                # Generate backfill + next day
                if backfill_start and backfill_end:
                    print(f"\nðŸ“… Generating backfill predictions...")
                    generate_future_predictions_range(
                        backfill_start,
                        backfill_end,
                        dry_run=args.dry_run,
                        ab_cutoff=args.ab_cutoff,
                        scr_timeout=args.scr_timeout,
                        scr_retries=args.scr_retries,
                    )
                
                print(f"\nðŸ“… Generating next day prediction...")
                generate_future_predictions_range(
                    next_day,
                    next_day,
                    dry_run=args.dry_run,
                    ab_cutoff=args.ab_cutoff,
                    scr_timeout=args.scr_timeout,
                    scr_retries=args.scr_retries,
                )
                
            elif choice == "2":
                start_str = input("Enter start date (DD-MM-YY): ").strip()
                end_str = input("Enter end date (DD-MM-YY): ").strip()
                start_date = parse_ddmmyy(start_str)
                end_date = parse_ddmmyy(end_str)
                generate_future_predictions_range(
                    start_date,
                    end_date,
                    dry_run=args.dry_run,
                    ab_cutoff=args.ab_cutoff,
                    scr_timeout=args.scr_timeout,
                    scr_retries=args.scr_retries,
                )
                
            elif choice == "3":
                print("Cancelled")
                sys.exit(0)
            else:
                print("ERROR: Invalid choice")
                sys.exit(1)
                
        except Exception as e:
            print(f"ERROR: {e}")
            sys.exit(1)
        
        return
    
    # Should not reach here
    print("ERROR: Invalid argument combination")
    sys.exit(1)


def main() -> None:
    """Main entry point for the console runner."""
    parser = argparse.ArgumentParser(
        description="Precise Predictor Console Runner - Backtest & Future Prediction Generation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    
    # Backtest arguments
    parser.add_argument("--backtest", action="store_true", 
                       help="Run in backtest mode")
    parser.add_argument(
        "--last",
        type=int,
        help="Number of days to backtest (use with --backtest). Common: 30/60/90/120/150/180/365",
    )
    parser.add_argument("--start", type=str, 
                       help="Start date for backtest (DD-MM-YY format)")
    parser.add_argument("--end", type=str, 
                       help="End date for backtest (DD-MM-YY format)")
    parser.add_argument(
        "--auto-generate-missing",
        dest="auto_generate_missing",
        action="store_true",
        default=True,
        help="Auto-generate missing predictions during backtest (default: ON)",
    )
    parser.add_argument(
        "--no-auto-generate-missing",
        dest="auto_generate_missing",
        action="store_false",
        help="Disable auto-generation of missing predictions during backtest",
    )
    
    # Future prediction arguments
    parser.add_argument("--generate-future", action="store_true", 
                       help="Generate future predictions")
    parser.add_argument("--from", dest="from_date", type=str, 
                       help="Start date for future generation (DD-MM-YY format)")
    parser.add_argument("--to", "--until", dest="to_date", type=str, 
                       help="End date for future generation (DD-MM-YY format)")
    
    # Common arguments
    parser.add_argument("--rebuild-metrics", action="store_true", 
                       help="Rebuild metrics from historical data before processing")
    parser.add_argument("--verbose", action="store_true",
                       help="Enable verbose logging for debugging")
    parser.add_argument("--dry-run", action="store_true",
                       help="Generate future ranges without writing files")
    parser.add_argument(
        "--ab-cutoff",
        choices=("prev", "same"),
        default="prev",
        help="AB snapshot cutoff: prev=D-1 or same=D (default: prev)",
    )
    parser.add_argument(
        "--scr-timeout",
        type=int,
        default=300,
        help="Timeout in seconds for SCR2 execution (default: 300)",
    )
    parser.add_argument(
        "--scr-retries",
        type=int,
        default=1,
        help="Retries for SCR2 on non-zero exit or timeout (default: 1)",
    )
    
    args = parser.parse_args()
    
    # Handle backtest mode
    if args.backtest:
        handle_backtest_mode(args)
    # Handle future generation mode
    elif args.generate_future:
        handle_future_generation_mode(args)
    else:
        run_interactive_display(
            scr_timeout=args.scr_timeout,
            scr_retries=args.scr_retries,
        )


if __name__ == "__main__":
    main()
